import cv2
import pytesseract
import re
import unicodedata
from typing import Dict, List, Tuple, Optional
try:
    import numpy as np  # used for bytes decoding
    _HAS_NUMPY = True
except Exception:
    np = None
    _HAS_NUMPY = False

# ƒê∆∞·ªùng d·∫´n Tesseract
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# C√°c tr∆∞·ªùng quan tr·ªçng (ti·∫øng Vi·ªát + ti·∫øng Anh + l·ªói OCR ph·ªï bi·∫øn)
FIELDS: Dict[str, List[str]] = {
    "student_card": ["the sinh vien", "th·∫ª sinh vi√™n", "the sv", "student card", "student id", "sinh vien", "sinhvien"],
    "university": [
        # Ti·∫øng Vi·ªát chu·∫©n
        "dai hoc", "ƒë·∫°i h·ªçc", "truong dai hoc", "tr∆∞·ªùng ƒë·∫°i h·ªçc",
        # Bi·∫øn th·ªÉ OCR nh·∫ßm
        "dai h·ªçc", "d·∫°i hoc", "daihoc", "ƒëaihoc", "university",
        # T√™n tr∆∞·ªùng ph·ªï bi·∫øn
        "duy tan", "duytan", "dtu", "dai hoc duy tan",
        # Keyword li√™n quan
        "truong", "tr∆∞·ªùng"
    ],
    "faculty": ["khoa", "khoaa", "faculty"],
    "major": ["nganh", "ng√†nh", "major", "field"],
    "class": ["lop", "l·ªõp", "class"],
    "mssv": ["ma sinh vien", "m√£ sinh vi√™n", "student code", "mssv", "masv"],
    "cccd": ["cccd", "can cuoc cong dan", "cƒÉn c∆∞·ªõc c√¥ng d√¢n", "citizen id"],
    "cmnd": ["cmnd", "chung minh nhan dan", "ch·ª©ng minh nh√¢n d√¢n", "identity card"],
    "edu_domain": [".edu.vn", ".edu", "edu.vn", "edu", "eduvn"]
}

# H√†m chu·∫©n h√≥a text OCR
def normalize_text(text: str) -> str:
    text = unicodedata.normalize("NFC", text)
    text = text.lower()
    text = re.sub(r"[^a-zA-Z0-9√°√†·∫£√£·∫°ƒÉ√¢ƒë√©√®·∫ª·∫Ω·∫π√™√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥∆°√∫√π·ªß≈©·ª•√Ω·ª≥·ª∑·ªπ·ªµ\s]", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

# Fuzzy match
def fuzzy_contains(text: str, keyword: str, threshold: int = 65) -> bool:
    t = text.lower()
    k = keyword.lower()
    # Simple partial check and crude token overlap ratio (no external deps)
    if k in t:
        return True
    # crude ratio: common token overlap
    t_tokens = set(re.split(r"\W+", t))
    k_tokens = set(re.split(r"\W+", k))
    inter = len(t_tokens & k_tokens)
    total = max(1, len(k_tokens))
    return (inter * 100 / total) >= threshold

# Ti·ªÅn x·ª≠ l√Ω ·∫£nh
def preprocess_image(image_path: str):
    img = cv2.imread(image_path)
    if img is None:
        return None
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Adaptive threshold
    thresh = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY, 31, 2
    )
    # Dilation + Erosion
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
    processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    return processed

# Ki·ªÉm tra CCCD (12 ch·ªØ s·ªë)
def extract_cccd(text: str) -> Optional[str]:
    # T√¨m c·∫£ s·ªë d√≠nh v√†o ch·ªØ v√† s·ªë ri√™ng bi·ªát
    matches = re.findall(r"\d{12}", text.replace(" ", "").replace("-", ""))
    return matches[0] if matches else None

# Ki·ªÉm tra MSSV (8-11 s·ªë, KH√îNG ph·∫£i 12 s·ªë CCCD)
def extract_mssv(text: str) -> Optional[str]:
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng v√† d·∫•u g·∫°ch ngang
    clean_text = text.replace(" ", "").replace("-", "")
    # T√¨m t·∫•t c·∫£ d√£y s·ªë 8-11 ch·ªØ s·ªë
    matches = re.findall(r"\d{8,11}", clean_text)
    # Lo·∫°i b·ªè c√°c s·ªë 12 ch·ªØ s·ªë (CCCD)
    matches = [m for m in matches if len(m) >= 8 and len(m) <= 11]
    return matches[0] if matches else None

# Ki·ªÉm tra c√≥ ch·ªØ CCCD ho·∫∑c CMND
def has_cccd_or_cmnd_keyword(text: str) -> bool:
    for kw in FIELDS["cccd"] + FIELDS["cmnd"]:
        if fuzzy_contains(text, kw, threshold=30):
            return True
    return False

# Ki·ªÉm tra URL .edu.vn ho·∫∑c .edu
def has_edu_domain(text: str) -> bool:
    # T√¨m domain .edu.vn ho·∫∑c .edu
    return bool(re.search(r"\.edu(\.vn)?", text, re.IGNORECASE))

# H√†m ki·ªÉm tra th·∫ª sinh vi√™n
def is_student_card(image_path: str) -> Tuple[bool, Dict[str, object]]:
    """Verify student card from an image path.

    Returns (valid, details) where details includes:
      - fields_matched: List[str]
      - mssv: Optional[str]
      - ocr_text: str
      - reasons: List[str]
    """
    img = preprocess_image(image_path)
    if img is None:
        return False, {"error": "Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh", "fields_matched": [], "mssv": None, "ocr_text": "", "reasons": ["·∫¢nh kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë∆∞·ªùng d·∫´n sai"]}

    text = pytesseract.image_to_string(img, lang="vie+eng")
    text = normalize_text(text)

    matched_fields: List[str] = []
    reasons: List[str] = []
    for field, keywords in FIELDS.items():
        if field == "edu_domain":
            # Ki·ªÉm tra ri√™ng cho edu domain
            if has_edu_domain(text):
                matched_fields.append(field)
        else:
            for kw in keywords:
                if fuzzy_contains(text, kw):
                    matched_fields.append(field)
                    break

    # Ki·ªÉm tra MSSV (8-11 ch·ªØ s·ªë)
    mssv = extract_mssv(text)
    if mssv:
        if "mssv" not in matched_fields:
            matched_fields.append("mssv")
    else:
        reasons.append("Kh√¥ng t√¨m th·∫•y m√£ s·ªë sinh vi√™n (8‚Äì11 ch·ªØ s·ªë)")

    # Ki·ªÉm tra c√≥ "Th·∫ª sinh vi√™n" ho·∫∑c "Student card"
    if "student_card" not in matched_fields:
        reasons.append("Kh√¥ng t√¨m th·∫•y ch·ªØ 'Th·∫ª sinh vi√™n' ho·∫∑c 'Student Card'")

    # Ki·ªÉm tra c√≥ "ƒê·∫°i h·ªçc" ho·∫∑c "University"
    if "university" not in matched_fields:
        reasons.append("Kh√¥ng t√¨m th·∫•y ch·ªØ 'ƒê·∫°i h·ªçc' ho·∫∑c 'University'")

    # Ki·ªÉm tra c√≥ domain .edu.vn ho·∫∑c .edu
    if "edu_domain" not in matched_fields:
        reasons.append("Kh√¥ng t√¨m th·∫•y domain .edu.vn ho·∫∑c .edu")

    # Heuristic: c·∫ßn √≠t nh·∫•t 2 trong c√°c tr∆∞·ªùng b·∫Øt bu·ªôc
    # (student_card, university, edu_domain, mssv)
    required_fields = ["student_card", "university", "edu_domain", "mssv"]
    matched_required = [f for f in matched_fields if f in required_fields]
    valid = len(matched_required) >= 2
    
    if not valid:
        reasons.append(f"Ch·ªâ t√¨m th·∫•y {len(matched_required)}/4 tr∆∞·ªùng b·∫Øt bu·ªôc (c·∫ßn √≠t nh·∫•t 2)")

    return valid, {
        "fields_matched": list(set(matched_fields)),
        "mssv": mssv,
        "ocr_text": text,
        "reasons": reasons,
    }

def verify_student_card_from_bytes(image_bytes: bytes) -> Tuple[bool, Dict[str, object]]:
    """Verify student card from raw image bytes (e.g., uploaded file).

    Decodes bytes, preprocesses, runs OCR and fuzzy match.
    T·ªêI ∆ØU NHANH: Ch·ªâ gi·ªØ preprocessing t·ªëi thi·ªÉu ƒë·ªÉ OCR nhanh nh·∫•t
    """
    import sys
    
    if not _HAS_NUMPY:
        return False, {"error": "Thi·∫øu th∆∞ vi·ªán numpy ƒë·ªÉ gi·∫£i m√£ ·∫£nh bytes", "fields_matched": [], "mssv": None, "ocr_text": "", "reasons": ["Vui l√≤ng c√†i ƒë·∫∑t numpy"]}
    
    print("[OCR] üì• ƒêang decode ·∫£nh...", file=sys.stderr, flush=True)
    try:
        nparr = cv2.imdecode(np.frombuffer(image_bytes, np.uint8), cv2.IMREAD_COLOR)
    except Exception:
        return False, {"error": "Kh√¥ng gi·∫£i m√£ ƒë∆∞·ª£c ·∫£nh t·ª´ bytes", "fields_matched": [], "mssv": None, "ocr_text": "", "reasons": ["D·ªØ li·ªáu ·∫£nh kh√¥ng h·ª£p l·ªá"]}

    # NHANH 1: Resize v·ªÅ k√≠ch th∆∞·ªõc T·ªêI ∆ØU (300px) ngay t·ª´ ƒë·∫ßu
    h, w = nparr.shape[:2]
    print(f"[OCR] Progress: 10% - K√≠ch th∆∞·ªõc g·ªëc: {w}x{h}", file=sys.stderr, flush=True)
    
    max_dim = max(h, w)
    target_size = 300  # Gi·∫£m xu·ªëng 300px ƒë·ªÉ x·ª≠ l√Ω c·ª±c nhanh
    
    if max_dim != target_size:
        scale = target_size / max_dim
        new_w = int(w * scale)
        new_h = int(h * scale)
        nparr = cv2.resize(nparr, (new_w, new_h), interpolation=cv2.INTER_AREA)
        print(f"[OCR] Progress: 20% - Resize xu·ªëng {new_w}x{new_h}", file=sys.stderr, flush=True)
    
    # NHANH 2: Grayscale + Ti·ªÅn x·ª≠ l√Ω ƒë·ªÉ c·∫£i thi·ªán OCR
    print("[OCR] Progress: 30% - Chuy·ªÉn grayscale v√† ti·ªÅn x·ª≠ l√Ω", file=sys.stderr, flush=True)
    gray = cv2.cvtColor(nparr, cv2.COLOR_BGR2GRAY)
    
    # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n nh·∫π cho text r√µ h∆°n
    gray = cv2.convertScaleAbs(gray, alpha=1.2, beta=10)
    
    # NHANH 3: OCR v·ªõi VI·ªÜT NAM + ANH
    print("[OCR] Progress: 40% - B·∫Øt ƒë·∫ßu Tesseract OCR (vie+eng)", file=sys.stderr, flush=True)
    # --oem 1: LSTM only
    # --psm 6: uniform text block (t·ªët cho th·∫ª SV)
    # D√πng "vie+eng" ƒë·ªÉ ƒë·ªçc ti·∫øng Vi·ªát
    text = pytesseract.image_to_string(gray, lang="vie+eng", config="--oem 1 --psm 6")
    print("[OCR] Progress: 100% - OCR ho√†n t·∫•t", file=sys.stderr, flush=True)
    text = normalize_text(text)
    
    # Log text ƒë√£ ph√¢n t√≠ch (RAW + Normalized)
    print(f"\n[OCR] üìù RAW Text (500 k√Ω t·ª± ƒë·∫ßu):", file=sys.stderr, flush=True)
    raw_text = pytesseract.image_to_string(gray, lang="vie+eng", config="--oem 1 --psm 6")
    print(raw_text[:500], file=sys.stderr, flush=True)
    print(f"\n[OCR] üìù Normalized text: {text[:300]}...", file=sys.stderr, flush=True)

    matched_fields: List[str] = []
    reasons: List[str] = []
    
    # KI·ªÇM TRA 6 TR∆Ø·ªúNG (4 c≈© + CCCD keyword + CCCD number)
    # 1. T√¨m MSSV (8-11 ch·ªØ s·ªë, KH√îNG ph·∫£i CCCD 12 s·ªë)
    mssv = extract_mssv(text)
    if mssv:
        matched_fields.append("mssv")
        print(f"[OCR] ‚úÖ T√¨m th·∫•y MSSV: {mssv}", file=sys.stderr, flush=True)
    else:
        reasons.append("Kh√¥ng t√¨m th·∫•y MSSV (8-11 ch·ªØ s·ªë)")
        print("[OCR] ‚ùå Kh√¥ng t√¨m th·∫•y MSSV", file=sys.stderr, flush=True)
    
    # 2. T√¨m "Th·∫ª sinh vi√™n" ho·∫∑c "Student Card"
    has_student_card = False
    for kw in FIELDS["student_card"]:
        if fuzzy_contains(text, kw, threshold=30):  # Gi·∫£m threshold xu·ªëng 30
            has_student_card = True
            matched_fields.append("student_card")
            print(f"[OCR] ‚úÖ T√¨m th·∫•y keyword: {kw}", file=sys.stderr, flush=True)
            break
    if not has_student_card:
        reasons.append("Kh√¥ng t√¨m th·∫•y 'Th·∫ª sinh vi√™n' ho·∫∑c 'Student Card'")
        print("[OCR] ‚ùå Kh√¥ng t√¨m th·∫•y 'Th·∫ª sinh vi√™n'", file=sys.stderr, flush=True)
    
    # 3. T√¨m "ƒê·∫°i h·ªçc" ho·∫∑c "University"
    has_university = False
    for kw in FIELDS["university"]:
        if fuzzy_contains(text, kw, threshold=30):
            has_university = True
            matched_fields.append("university")
            print(f"[OCR] ‚úÖ T√¨m th·∫•y keyword: {kw}", file=sys.stderr, flush=True)
            break
    if not has_university:
        reasons.append("Kh√¥ng t√¨m th·∫•y 'ƒê·∫°i h·ªçc' ho·∫∑c 'University'")
        print("[OCR] ‚ùå Kh√¥ng t√¨m th·∫•y 'ƒê·∫°i h·ªçc'", file=sys.stderr, flush=True)
    
    # 4. T√¨m domain .edu.vn ho·∫∑c .edu
    has_edu = has_edu_domain(text)
    if has_edu:
        matched_fields.append("edu_domain")
        print("[OCR] ‚úÖ T√¨m th·∫•y .edu domain", file=sys.stderr, flush=True)
    else:
        reasons.append("Kh√¥ng t√¨m th·∫•y .edu domain")
        print("[OCR] ‚ùå Kh√¥ng t√¨m th·∫•y .edu domain", file=sys.stderr, flush=True)
    
    # 5. T√¨m ch·ªØ CCCD ho·∫∑c CMND
    has_id_keyword = has_cccd_or_cmnd_keyword(text)
    if has_id_keyword:
        matched_fields.append("cccd_cmnd_keyword")
        print("[OCR] ‚úÖ T√¨m th·∫•y ch·ªØ CCCD/CMND", file=sys.stderr, flush=True)
    else:
        reasons.append("Kh√¥ng t√¨m th·∫•y ch·ªØ CCCD ho·∫∑c CMND")
        print("[OCR] ‚ùå Kh√¥ng t√¨m th·∫•y ch·ªØ CCCD/CMND", file=sys.stderr, flush=True)
    
    # 6. T√¨m s·ªë CCCD (12 ch·ªØ s·ªë)
    cccd_number = extract_cccd(text)
    if cccd_number:
        matched_fields.append("cccd_number")
        print(f"[OCR] ‚úÖ T√¨m th·∫•y s·ªë CCCD: {cccd_number}", file=sys.stderr, flush=True)
    else:
        reasons.append("Kh√¥ng t√¨m th·∫•y s·ªë CCCD (12 ch·ªØ s·ªë)")
        print("[OCR] ‚ùå Kh√¥ng t√¨m th·∫•y s·ªë CCCD", file=sys.stderr, flush=True)
    
    # LOGIC: Ch·ªâ c·∫ßn 1/6 tr∆∞·ªùng l√† PASS (c·ª±c k·ª≥ d·ªÖ d√†ng)
    all_fields = ["mssv", "student_card", "university", "edu_domain", "cccd_cmnd_keyword", "cccd_number"]
    matched_required = [f for f in matched_fields if f in all_fields]
    valid = len(matched_required) >= 1
    
    print(f"\n[OCR] üìä K·∫øt qu·∫£: {len(matched_required)}/6 tr∆∞·ªùng -> {'PASS' if valid else 'FAIL'}", file=sys.stderr, flush=True)
    
    if not valid:
        reasons.append(f"Kh√¥ng t√¨m th·∫•y b·∫•t k·ª≥ tr∆∞·ªùng h·ª£p l·ªá n√†o (c·∫ßn √≠t nh·∫•t 1/6)")

    return valid, {
        "fields_matched": list(set(matched_fields)),
        "mssv": mssv,
        "ocr_text": text,
        "reasons": reasons,
    }

# =======================
# V√≠ d·ª• s·ª≠ d·ª•ng
# =======================
if __name__ == "__main__":
    import sys
    import json
    args = sys.argv[1:]

    # Usage:
    #   python student_card_filter.py --json <image_path>
    #   python student_card_filter.py --stdin  (reads image bytes from stdin)
    if len(args) >= 2 and args[0] == "--json":
        path = args[1]
        valid, details = is_student_card(path)
        print(json.dumps({"valid": valid, **details}, ensure_ascii=False))
        sys.exit(0)
    elif len(args) == 1 and args[0] == "--stdin":
        data = sys.stdin.buffer.read()
        valid, details = verify_student_card_from_bytes(data)
        print(json.dumps({"valid": valid, **details}, ensure_ascii=False))
        sys.exit(0)
    else:
        # Demo mode
        image = "the_sinh_vien.jpg"
        valid, details = is_student_card(image)
        print("===== OCR TEXT =====")
        print(details.get("ocr_text", ""))
        if valid:
            print("\nüî∞ ·∫¢nh l√† TH·∫∫ SINH VI√äN!")
        else:
            print("\n‚õî KH√îNG ph·∫£i th·∫ª sinh vi√™n.")
        print("Tr∆∞·ªùng tr√πng:", details.get("fields_matched", []))
        print("M√£ s·ªë sinh vi√™n:", details.get("mssv"))
        if details.get("reasons"):
            print("L√Ω do:", ", ".join(details["reasons"]))